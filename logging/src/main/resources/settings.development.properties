application.build.number=-1
application.build.datetime=
application.build.branch=
application.build.url=http://hudson.playpen.gravity.com/job/InterestServiceDeploy/50/
application.environment=dev
application.role.default=DEVELOPMENT
#com.gravity.settings.force.production.robbie=true
#application.role.default.robbie=IGI_GMS
#application.role.default.evictor=IGI_GMS
application.role.default.runger=LIVE_TRAFFIC
#application.role.default.akash=ONTOLOGY_MANAGEMENT
#application.role.default.tchappell=CAMPAIGN_MANAGEMENT
#application.role.default.runger=RECO_MON
#application.role.default.erik=ARCHIVER
application.role.default.tbenavides14=RECO_MON
#application.role.GravityOpss-MacBook-Pro.local=SEARCH_INDEXING
application.role.type.API_ROLE=com.gravity.api.ApiRole
application.role.type.API_ROLE_AOL=com.gravity.api.ApiRole
application.role.type.API_CLICKS=com.gravity.api.ApiRole
application.role.type.WIDGET_LOADER=com.gravity.api.ApiRole
application.role.type.LANDING_PAGES=com.gravity.api.ApiRole
application.role.type.INTEREST_DEV=com.gravity.api.InterestStageRole
application.role.type.INTEREST_STAGE=com.gravity.api.InterestStageRole
application.role.type.HIGHLIGHTER=com.gravity.api.ApiRole
application.role.type.ALGO_SETTINGS=com.gravity.api.AlgoSettingsRole
application.role.type.ONTOLOGY_MANAGEMENT=com.gravity.interests.jobs.intelligence.OntologyManagementRole
application.role.type.CLICKSTREAM=com.gravity.insights.clickstream.realtime.ClickstreamRealtimeRole
application.role.type.INGEST_AOL=com.gravity.insights.barnacle.IngestAolRole
application.role.type.BEACON=com.gravity.insights.beacons.api.BeaconRole
application.role.type.BEACON_FAILOVER=com.gravity.insights.beacons.api.BeaconRole
application.role.type.ARCHIVER=com.gravity.insights.archiver.logger.ArchiverRole
application.role.type.CRAWLER=com.gravity.insights.crawler.CrawlerRole
application.role.type.DATAFEEDS=com.gravity.insights.datafeeds.DataFeedsRole
application.role.type.INTEREST_INTELLIGENCE=com.gravity.interests.jobs.intelligence.InterestIntelligenceRole
application.role.type.IGI_GMS=com.gravity.interests.jobs.intelligence.InterestIntelligenceRole
application.role.type.IGI_GMS_FAILOVER=com.gravity.interests.jobs.intelligence.InterestIntelligenceRole
application.role.type.INTEREST_PERSONALIZATION=com.gravity.interests.jobs.intelligence.workflows.personalization.v1.PersonalizationV1Role
application.role.type.INTEREST_INTELLIGENCE_OPERATIONS=com.gravity.interests.jobs.intelligence.InterestIntelligenceOperationsRole
application.role.type.METRICS_SCOPED=com.gravity.interests.jobs.intelligence.ScopedMetricsRole
application.role.type.METRICS_SCOPED_INFERENCE=com.gravity.interests.jobs.intelligence.ScopedMetricsRole
application.role.type.METRICS_LIVE=com.gravity.interests.jobs.intelligence.LiveScopedMetricsRole
application.role.type.USERS_ROLE=com.gravity.interests.jobs.intelligence.UsersRole
application.role.type.REPORT_GENERATION=com.gravity.interests.graphs.graphing.ReportGenerationRole
application.role.type.WIDGETS_FAILOVER=com.gravity.api.WidgetFailoverRole
application.role.type.EXTENSION_API=com.gravity.api.ApiRole
application.role.type.DEVELOPMENT=com.gravity.api.DevelopmentRole
application.role.type.MANAGEMENT=com.gravity.api.ManagementRole
application.role.type.RECOGENERATION=com.gravity.api.RecoGenerationRole
application.role.type.RECO_STORAGE=com.gravity.api.RecoStorageRole
//application.role.type.RTB_PROC=com.gravity.insights.rtb.saturn.SaturnRTBProcessorRole
//application.role.type.RTB_DATACOLLECTOR=com.gravity.insights.rtb.saturn.SaturnRemoteDataRole
application.role.type.API_RTB=com.gravity.api.SaturnRTBApiRole
application.role.type.API_RTB_IAD=com.gravity.api.SaturnRTBApiRole
application.role.type.RTB_DATACOLLECTOR_EAST=com.gravity.insights.rtb.saturn.SaturnRemoteDataRoleEast
application.role.type.RTB_STAGE=com.gravity.api.SaturnRTBApiRole
application.role.type.RTB_CONTROL=com.gravity.insights.rtb.saturn.SaturnRTBControllerRole
application.role.type.POC=com.gravity.api.ApiRole
application.role.type.WORKFLOW=com.gravity.interests.jobs.WorkflowRole
application.role.type.CAMPAIGN_MANAGEMENT=com.gravity.api.CampaignManagementRole
application.role.type.LIVE_TRAFFIC=com.gravity.api.livetraffic.LiveTrafficRole
application.role.type.USER_SYNC=com.gravity.api.UserSyncRole
application.role.type.STATIC_WIDGETS=com.gravity.api.StaticWidgetApiRole
application.role.type.URL_VALIDATION=com.gravity.api.UrlValidationRole
application.role.type.RECOGENERATION_FAILOVER=com.gravity.api.RecogenerationFailoverRole
application.role.type.REMOTE_RECOS=com.gravity.interests.jobs.intelligence.RemoteCacheRole
operations.environments.types.LOCAL_ENV="Local development"
operations.environemtns.types.LOCAL_TEST_CLUSTER_ENV="Local development with test cluster"
operations.environments.types.DEVELOPMENT_ENV="Development environment"
operations.environments.types.STAGE_ENV="Staging environment"
operations.environments.types.PRODUCTION_ENV="Production environment"

operations.enable-prod-remoting.ahiniker=false

operations.environment=LOCAL_ENV

operations.smtp.host=smtp.prod.grv

#operations.is.production.server.robbie=true

dlug.auto.reject.and.notify.enabled=false
dlug.ad.unit.reorder.around.ad.enabled=true
url.validation.server.enabled=true

zookeeper.servers.aws=10.116.175.157:2181,10.116.164.171:2181,10.116.178.137:2181
zookeeper.servers.dev=10.116.173.171:2181
zookeeper.servers.dev.akash=10.116.175.157:2181,10.116.164.171:2181,10.116.178.137:2181
zookeeper.servers.dev.cyberpunk=10.116.175.157:2181,10.116.164.171:2181,10.116.178.137:2181

service.root.tracelogger=false
service.root.tracelogger.chris=false
service.root.tracelogger.jim=true
service.root.tracelogger.robbie=false
service.root.tracelogger.tchappell=true
service.root.tracelogger.Unger=true
service.root.tracelogger.evictor=true
service.root.tracelogger.ahiniker=false
service.root.tracelogger.asquassabia=true
service.root.tracelogger.alsq=true
service.root.tracelogger.jason.sylvester=true

service.root.tracelogger.operations=false
service.root.tracelogger.for.packages.robbie=com.gravity.interests.jobs.intelligence.operations.ArticleService,com.gravity.data.reporting.ElasticSearchQueryService

service.root.deprecated.throwExceptions=false

service.roledata.defaultSocketSettings.evictor=true
service.roledata.defaultSocketSettings.agrealish14=true

#webserverrunner.context.path=
#webserverrunner.context.path.ahiniker=/gravity-interests-web-0.5-SNAPSHOT-prod
webServerRunner.audioFeedback=true
webServerRunner.audioFeedback.agrealish14=false

# Geo Database
geo.database.provider=netacuity


hadoop.environment.default=development
#change this value to dlug to use dlug cluster by default
hadoop.hdfs.cluster.default.production=main
hadoop.hdfs.cluster.default.development=main

hadoop.hbase.pool.size=2
hadoop.hbase.pool.size.IGI_GMS=5

# Recommendations
recommendation.retrieval.timeout=1h

#All Hadoop clusters. this should be the same for all configs because it has all environments

# Current Production / Peak Hadoop Clusters

# Front-end
production.main.hadoop.hdfs.dfs.nameservices=nameservice1
production.main.hadoop.hdfs.filesystem=hdfs://nameservice1
production.main.hadoop.hdfs.dfs.client.failover.proxy.provider.nameservice1=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
production.main.hadoop.hdfs.dfs.ha.automatic-failover.enabled.nameservice1=true
production.main.hadoop.hdfs.dfs.ha.namenodes.nameservice1=namenode1117,namenode1460
production.main.hadoop.hdfs.dfs.namenode.rpc-address.nameservice1.namenode1117=sjc1-hadoopm06.prod.grv:8020
production.main.hadoop.hdfs.dfs.namenode.rpc-address.nameservice1.namenode1460=sjc1-hadoopm07.prod.grv:8020
production.main.hadoop.hdfs.ha.zookeeper.quorum=sjc1-hzk0001.prod.grv:2181,sjc1-hzk0002.prod.grv:2181,sjc1-hzk0003.prod.grv:2181
production.main.hbase.zookeeper.quorum=sjc1-hzk0001.prod.grv,sjc1-hzk0002.prod.grv,sjc1-hzk0003.prod.grv
production.main.hadoop.zookeeper.clientport=2181
production.main.spark.eventLog.dir=hdfs://nameservice1/user/spark/applicationHistory
production.main.spark.yarn.historyServer.address=http://sjc1-hadoopm07.prod.grv:18088
production.main.hdfs.config.url=http://clouderamanager/cmf/services/52/client-config
production.main.yarn.config.url=http://clouderamanager/cmf/services/120/client-config
production.main.hbase.config.url=http://clouderamanager/cmf/services/54/client-config
production.main.hive.config.url=http://clouderamanager/cmf/services/63/client-config

# DLUG aka failover
production.dlug.hadoop.hdfs.dfs.nameservices=failovernameservice
production.dlug.hadoop.hdfs.filesystem=hdfs://failovernameservice
production.dlug.hadoop.hdfs.dfs.client.failover.proxy.provider.failovernameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
production.dlug.hadoop.hdfs.dfs.ha.automatic-failover.enabled.failovernameservice=true
production.dlug.hadoop.hdfs.dfs.ha.namenodes.failovernameservice=namenode3384,namenode3354
production.dlug.hadoop.hdfs.dfs.namenode.rpc-address.failovernameservice.namenode3384=sjc1-hdpwtfm01.prod.grv:8020
production.dlug.hadoop.hdfs.dfs.namenode.rpc-address.failovernameservice.namenode3354=sjc1-hdpwtfm02.prod.grv:8020
production.dlug.hadoop.hdfs.ha.zookeeper.quorum=sjc1-hdpwtfm01.prod.grv:2181,sjc1-hdpwtfm02.prod.grv:2181,sjc1-hdpwtfm03.prod.grv:2181
production.dlug.hbase.zookeeper.quorum=sjc1-hdpwtfm02.prod.grv,sjc1-hdpwtfm03.prod.grv,sjc1-hdpwtfm01.prod.grv
production.dlug.hadoop.zookeeper.clientport=2181
production.dlug.spark.eventLog.dir=hdfs://failovernameservice/user/spark/applicationHistory
production.dlug.spark.yarn.historyServer.address=http://sjc1-hadoopm07.prod.grv:18088
#production.dlug.hdfs.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/171/client-config
#production.dlug.hbase.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/170/client-config
#production.dlug.yarn.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/169/client-config

#OLTP (the same as front end in this environment)
production.oltp.hadoop.hdfs.dfs.nameservices=nameservice1
production.oltp.hadoop.hdfs.filesystem=hdfs://nameservice1
production.oltp.hadoop.hdfs.dfs.client.failover.proxy.provider.nameservice1=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
production.oltp.hadoop.hdfs.dfs.ha.automatic-failover.enabled.nameservice1=true
production.oltp.hadoop.hdfs.dfs.ha.namenodes.nameservice1=namenode1117,namenode1460
production.oltp.hadoop.hdfs.dfs.namenode.rpc-address.nameservice1.namenode1117=sjc1-hadoopm06.prod.grv:8020
production.oltp.hadoop.hdfs.dfs.namenode.rpc-address.nameservice1.namenode1460=sjc1-hadoopm07.prod.grv:8020
production.oltp.hadoop.hdfs.ha.zookeeper.quorum=sjc1-hzk0001.prod.grv:2181,sjc1-hzk0002.prod.grv:2181,sjc1-hzk0003.prod.grv:2181
production.oltp.hbase.zookeeper.quorum=sjc1-hzk0001.prod.grv,sjc1-hzk0002.prod.grv,sjc1-hzk0003.prod.grv
production.oltp.hadoop.zookeeper.clientport=2181
production.oltp.spark.eventLog.dir=hdfs://nameservice1/user/spark/applicationHistory
production.oltp.spark.yarn.historyServer.address=http://sjc1-hadoopm07.prod.grv:18088
production.oltp.hdfs.config.url=http://clouderamanager/cmf/services/52/client-config
production.oltp.yarn.config.url=http://clouderamanager/cmf/services/120/client-config
production.oltp.hbase.config.url=http://clouderamanager/cmf/services/54/client-config
production.oltp.hive.config.url=http://clouderamanager/cmf/services/63/client-config

# AWS clusters

# Front-end
aws.main.hadoop.hdfs.dfs.nameservices=jpc-nameservice
aws.main.hadoop.hdfs.filesystem=hdfs://jpc-nameservice
aws.main.hadoop.hdfs.dfs.client.failover.proxy.provider.jpc-nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
aws.main.hadoop.hdfs.dfs.ha.automatic-failover.enabled.jpc-nameservice=true
aws.main.hadoop.hdfs.dfs.ha.namenodes.jpc-nameservice=namenode236,namenode217
aws.main.hadoop.hdfs.dfs.namenode.rpc-address.jpc-nameservice.namenode236=ip-10-116-165-162.aws.prod.grv:8020
aws.main.hadoop.hdfs.dfs.namenode.rpc-address.jpc-nameservice.namenode217=ip-10-116-165-163.aws.prod.grv:8020
aws.main.hadoop.hdfs.ha.zookeeper.quorum=10.116.167.177:2181,10.116.166.179:2181,10.116.166.180:2181
aws.main.hbase.zookeeper.quorum=10.116.167.177,10.116.166.179,10.116.166.180
aws.main.hadoop.zookeeper.clientport=2181
aws.main.spark.eventLog.dir=hdfs://jpc-nameservice/user/spark/applicationHistory
aws.main.spark.yarn.historyServer.address=http://ip-10-116-165-108.aws.prod.grv:18088
#aws.main.hadoop.config.url=

# DLUG aka failover (still uses peak for now)
aws.dlug.hadoop.hdfs.dfs.nameservices=failovernameservice
aws.dlug.hadoop.hdfs.filesystem=hdfs://failovernameservice
aws.dlug.hadoop.hdfs.dfs.client.failover.proxy.provider.failovernameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
aws.dlug.hadoop.hdfs.dfs.ha.automatic-failover.enabled.failovernameservice=true
aws.dlug.hadoop.hdfs.dfs.ha.namenodes.failovernameservice=namenode3384,namenode3354
aws.dlug.hadoop.hdfs.dfs.namenode.rpc-address.failovernameservice.namenode3384=sjc1-hdpwtfm01.prod.grv:8020
aws.dlug.hadoop.hdfs.dfs.namenode.rpc-address.failovernameservice.namenode3354=sjc1-hdpwtfm02.prod.grv:8020
aws.dlug.hadoop.hdfs.ha.zookeeper.quorum=sjc1-hdpwtfm01.prod.grv:2181,sjc1-hdpwtfm02.prod.grv:2181,sjc1-hdpwtfm03.prod.grv:2181
aws.dlug.hbase.zookeeper.quorum=sjc1-hdpwtfm02.prod.grv,sjc1-hdpwtfm03.prod.grv,sjc1-hdpwtfm01.prod.grv
aws.dlug.hadoop.zookeeper.clientport=2181
aws.dlug.spark.eventLog.dir=hdfs://failovernameservice/user/spark/applicationHistory
aws.dlug.spark.yarn.historyServer.address=http://ip-10-116-162-130.aws.prod.grv:19888/
#aws.dlug.hdfs.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/171/client-config
#aws.dlug.hbase.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/170/client-config
#aws.dlug.yarn.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/169/client-config

# OLTP - still JPC
aws.oltp.hadoop.hdfs.dfs.nameservices=jpc-nameservice
aws.oltp.hadoop.hdfs.filesystem=hdfs://jpc-nameservice
aws.oltp.hadoop.hdfs.dfs.client.failover.proxy.provider.jpc-nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
aws.oltp.hadoop.hdfs.dfs.ha.automatic-failover.enabled.jpc-nameservice=true
aws.oltp.hadoop.hdfs.dfs.ha.namenodes.jpc-nameservice=namenode236,namenode217
aws.oltp.hadoop.hdfs.dfs.namenode.rpc-address.jpc-nameservice.namenode236=ip-10-116-165-162.aws.prod.grv:8020
aws.oltp.hadoop.hdfs.dfs.namenode.rpc-address.jpc-nameservice.namenode217=ip-10-116-165-163.aws.prod.grv:8020
aws.oltp.hadoop.hdfs.ha.zookeeper.quorum=10.116.167.177:2181,10.116.166.179:2181,10.116.166.180:2181
aws.oltp.hbase.zookeeper.quorum=10.116.167.177,10.116.166.179,10.116.166.180
aws.oltp.hadoop.zookeeper.clientport=2181
aws.oltp.spark.eventLog.dir=hdfs://jpc-nameservice/user/spark/applicationHistory
aws.oltp.spark.yarn.historyServer.address=http://ip-10-116-165-108.aws.prod.grv:18088
#aws.main.hadoop.config.url=

#DEVELOPMENT Hadoop Clusters

#front end
development.main.hadoop.hdfs.dfs.nameservices=dev-nameservice
development.main.hadoop.hdfs.filesystem=hdfs://dev-nameservice
development.main.hadoop.hdfs.dfs.client.failover.proxy.provider.dev-nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
development.main.hadoop.hdfs.dfs.ha.automatic-failover.enabled.dev-nameservice=true
development.main.hadoop.hdfs.dfs.ha.namenodes.dev-nameservice=namenode1944,namenode1939
development.main.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1944=ip-10-116-173-171.aws.prod.grv:8022
development.main.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1939=ip-10-116-173-172.aws.prod.grv:8022
development.main.hadoop.hdfs.ha.zookeeper.quorum=10.116.173.171:2181,10.116.173.172:2181,10.116.172.5:2181
development.main.hbase.zookeeper.quorum=10.116.173.171,10.116.173.172,10.116.172.5
development.main.hadoop.zookeeper.clientport=2181
development.main.spark.eventLog.dir=hdfs://dev-nameservice/user/spark/applicationHistory
development.main.spark.yarn.historyServer.address=http://ip-10-116-172-5.aws.prod.grv:18088
#development.main.hdfs.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/95/client-config
#development.main.hbase.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/186/client-config
#development.main.yarn.config.url=http://clouderamanager.aws.prod.grv:7180/cmf/services/183/client-config


#dlug aka failover
development.dlug.hadoop.hdfs.dfs.nameservices=dev-nameservice
development.dlug.hadoop.hdfs.filesystem=hdfs://dev-nameservice
development.dlug.hadoop.hdfs.dfs.client.failover.proxy.provider.dev-nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
development.dlug.hadoop.hdfs.dfs.ha.automatic-failover.enabled.dev-nameservice=true
development.dlug.hadoop.hdfs.dfs.ha.namenodes.dev-nameservice=namenode1944,namenode1939
development.dlug.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1944=ip-10-116-173-171.aws.prod.grv:8022
development.dlug.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1939=ip-10-116-173-172.aws.prod.grv:8022
development.dlug.hadoop.hdfs.ha.zookeeper.quorum=10.116.173.171:2181,10.116.173.172:2181,10.116.172.5:2181
development.dlug.hbase.zookeeper.quorum=10.116.173.171,10.116.173.172,10.116.172.5
development.dlug.hadoop.zookeeper.clientport=2181
development.dlug.spark.eventLog.dir=hdfs://dev-nameservice/user/spark/applicationHistory
development.dlug.spark.yarn.historyServer.address=http://ip-10-116-172-5.aws.prod.grv:18088

#oltp (the same as front end in this environment)
development.oltp.hadoop.hdfs.dfs.nameservices=dev-nameservice
development.oltp.hadoop.hdfs.filesystem=hdfs://dev-nameservice
development.oltp.hadoop.hdfs.dfs.client.failover.proxy.provider.dev-nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
development.oltp.hadoop.hdfs.dfs.ha.automatic-failover.enabled.dev-nameservice=true
development.oltp.hadoop.hdfs.dfs.ha.namenodes.dev-nameservice=namenode1944,namenode1939
development.oltp.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1944=ip-10-116-173-171.aws.prod.grv:8022
development.oltp.hadoop.hdfs.dfs.namenode.rpc-address.dev-nameservice.namenode1939=ip-10-116-173-172.aws.prod.grv:8022
development.oltp.hadoop.hdfs.ha.zookeeper.quorum=10.116.173.171:2181,10.116.173.172:2181,10.116.172.5:2181
development.oltp.hbase.zookeeper.quorum=10.116.173.171,10.116.173.172,10.116.172.5
development.oltp.hadoop.zookeeper.clientport=2181
development.oltp.spark.eventLog.dir=hdfs://dev-nameservice/user/spark/applicationHistory
development.oltp.spark.yarn.historyServer.address=http://ip-10-116-172-5.aws.prod.grv:18088


#hadoop.zookeeper.quorum.DEVELOPMENT_ENV=10.116.173.171
#hadoop.zookeeper.quorum.BUILD_ENV=10.116.173.171
#hadoop.hdfs.filesystem.DEVELOPMENT_ENV=hdfs://10.116.173.171:9000
#hadoop.hdfs.filesystem.BUILD_ENV=hdfs://10.116.173.171:9000

memcached.hosts=10.116.169.210:11211 10.116.163.21:11211
memcached.hosts.DEVELOPMENT_ENV=10.116.187.33:11211
memcached.hosts.BUILD_ENV=10.116.187.33:11211

gms.lucene.autoindex=false
gms.lucene.autoindex.IGI_GMS_FAILOVER=true
gms.lucene.autoindex.IGI_GMS=true
gms.lucene.autoindex.robbie=true
gms.lucene.autoindex.evictor=false
gms.lucene.autoindex.jdecamp14=true
gms.lucene.autoindex.tchappell=true

gms.lucene.autoindex.include.metrics=true

gms.article.index.use.elastic=true

gms.generate.static.widgets.robbie=false

recommendation.log.hdfsStagingSequenceDir=/user/gravity/devStageLogs.sequence/
recommendation.log.hdfsAvroDir=/user/gravity/devLogs.avro/
recommendation.log.hdfsWriteAvroDir=/user/gravity/devLogWriting.avro/
recommendation.log.inputLockPath=/devLogStage/inputLocks/
recommendation.log.lastProcessedPath=/devLogStage/lastProcessed/
recommendation.log.processingPath=/devLogStage/processing/
recommendation.log.outputLocksPath=/devLogStage/outputLocks2/
recommendation.log.processingLockPath=/devLogStage/processingLocks/
recommendation.log.logImpressionServed=false
recommendation.log.logImpressionServed.evictor=true

virality.queue.host=activemq.aws.prod.grv
virality.queue.port=9090
virality.queue.content.host=activemq.aws.prod.grv
virality.queue.content.port=9092
virality.queue.dead.transactions.host=activemq.aws.prod.grv
virality.queue.dead.transactions.port=9093
virality.queue.storage=/opt/interests/data/viralityqueue/

diskmounts.magellan=/tmp

graphing.algorithm.version=1
graphing.use.popqueue=false
graphing.use.ign.cache=false
graphing.enqueue.events=false
graphing.recrawl.task.enabled=false

# master redis cache server for the insights front end UI displays
insights.redis.master01=127.0.0.1
insights.redis.master02=127.0.0.1

# holds the master database that insights web pulls data from to show customers
insights.roost.master.host=db-roost1.prod.grv
insights.roost.master.username=
insights.roost.master.password=
insights.roost.master.database=roost1
insights.roost.dev.host=db-development.aws.prod.grv
insights.roost.dev.username=
insights.roost.dev.password=
insights.roost.dev.database=roost1-dev

# master lizard database that holds the crawling information
insights.lizard.master.host=127.0.0.1
insights.lizard.master.username=
insights.lizard.master.password=
insights.lizard.master.database=lizard

# the master database for content / blog data rollups for insights web
insights.content.master.host=vba-db02
insights.content.master.username=
insights.content.master.password=
insights.content.master.database=content

insights.clickstream.consumername.redis=DevRedisConsumer
insights.clickstream.consumername.newarticle=DevNewArticleBeaconConsumer
insights.clickstream.consumername.virality=DevViralityConsumer


insights.boomerang.imagemagick.convert.path=/opt/local/bin/convert
insights.boomerang.imagemagick.identify.path=/opt/local/bin/identify
insights.boomerang.images.temp.path=/opt/goose

insights.beacons.goJsDev=true

# AWS data warehouse settings
hiveaws.driver=org.apache.hive.jdbc.HiveDriver
hiveaws.url=jdbc:hive2://ip-10-116-166-64.aws.prod.grv:10000/default
hiveaws.username=
hiveaws.password=

# AWS impala connection settings
impalaaws.driver=org.apache.hive.jdbc.HiveDriver
impalaaws.url=jdbc:hive2://impala-tools-dev.aws.prod.grv:21050/;auth=noSasl
impalaaws.username=interest_service

# everyonegraph database settings
eg.db=everyone_graph
eg.db.write.host=db-everyonegraph
eg.db.write.user=
eg.db.write.password=
eg.db.write.port=3306

# job_tracking_history db settings
jt.db=job_tracking_history
jt.db.write.host=db-jobtrackinghistory
jt.db.write.user=
jt.db.write.password=
jt.db.write.port=3306

# kpi database settings
kpi.db=gravitykpi
kpi.db.write.host=db-gravitykpi
kpi.db.write.user=
kpi.db.write.password=
kpi.db.write.port=3306

# aws reporting
aws.driver=org.h2.Driver
aws.host=%s
aws.db=grvreports
# For standalone server, can be browsed using H2 web
#aws.user=sa
#aws.password=
#aws.conn=jdbc:h2:tcp://localhost/~/%s;
# For in-memory, cannot be browsed using H2 web
aws.user=
aws.password=
aws.conn=jdbc:h2:mem:%s;DB_CLOSE_DELAY=-1;

/**  POSTGRES  **/
# job info database settings
jn.db=Reporting
jn.db.write.host=db-reporting
jn.db.write.user=
jn.db.write.password=
jn.db.write.port=5432


# POSTGRES END

# various amazon gravity and partner settings
conduit.amazon.key.access=
conduit.amazon.key.secret=
conduit.amazon.bucket=gravityevents

gravity.amazon.key.access=
gravity.amazon.key.secret=
gravity.amazon.bucket=gravityevents

gravity.datamarts.s3.key.access=
gravity.datamarts.s3.key.secret=

gravity.aoldailydump.key.access=
gravity.aoldailydump.key.secret=
gravity.aoldailydump.destination.aws.bucket=aol-14p-datadump

grvjson.amazon.key.access=
grvjson.amazon.key.secret=
grvjson.amazon.bucket=grv-json
grvjson.amazon.baseurl=https://s3-us-west-2.amazonaws.com/grv-json/grv-jsonp/
grvjson.amazon.cdnbaseurl=http://jsonp.grvcdn.com/grv-jsonp/
com.amazonaws.sdk.disableCertChecking=true

grvinterestimages.amazon.key.access=
grvinterestimages.amazon.key.secret=
grvinterestimages.amazon.bucket=grv-interestimages
grvinterestimages.amazon.baseurl=https://s3-us-west-2.amazonaws.com/grv-interestimages/
grvinterestimages.amazon.cdnbaseurl=http://interestimages.grvcdn.com/

grv-recogen.amazon.key.access=
grv-recogen.amazon.key.secret=
grv-recogen.amazon.bucket=grv-recogen
grv-recogen.amazon.directory=prod

grv-app-overrides.amazon.key.access=
grv-app-overrides.amazon.key.secret=
grv-app-overrides.amazon.bucket=grv-app-overrides
grv-app-overrides.amazon.directory=production

grv-unit-test.amazon.key.access=
grv-unit-test.amazon.key.secret=
grv-unit-test.amazon.bucket=gravity-unit-test

#GetFromRemote.AllCampaignMeta.erik=true
#GetFromRemote.AllSitePlacementMeta.erik=true
#GetFromRemote.AllSiteMeta.erik=true

GetFromRemote.AllCampaignMeta=true
GetFromRemote.AllSitePlacementMeta=true
GetFromRemote.AllSiteMeta=true

# --- EMAIL NOTIFICATIONS -- #
# job processing email address for notifications
processing.jobs.email.notify=processingjobs@gravity.com

# collaborative filtering settings
crystal.redis.server=localhost

# weights for various article scores
newspaper.score.weight=1.0
cf.score.weight=1.0

#Virtuoso instance for ontology
virtuoso.username=
virtuoso.password=

#Virtuoso instance for interest graph
interests.virtuoso.username=
interests.virtuoso.password=
virtuoso.location=jdbc:virtuoso://grv-graph01:1111/charset=UTF-8/log_enable=2

#Interests Hibernate settings
interests.hibernate.useshards=true
interests.hibernate.content.shards.count=2
interests.hibernate.content.shards.username=
interests.hibernate.content.shards.password=
interests.hibernate.content.shard0.host=localhost
interests.hibernate.content.shard1.host=localhost

interests.hibernate.people.shards.count=2
interests.hibernate.people.shards.username=
interests.hibernate.people.shards.password=
interests.hibernate.people.shard0.host=localhost
interests.hibernate.people.shard1.host=localhost

#Insights Datamart settings
insights.datamart.shards.count=2
insights.datamart.shards.username=
insights.datamart.shards.password=
insights.datamart.shard0.host=localhost
insights.datamart.shard1.host=localhost


graph.default=interests.virtuoso
graph.default.depth=3
ontology.graph.directory=/opt/interests/data2
#ontology.graph.name.default=graph_concept
ontology.graph.name.default=graph.2015.04
ontology.graph.population.directory=/opt/interests/testdata/populatedgraph
ontology.graph.concepts.maxreturned=40
ontology.graph.regraphThreads = 24
ontology.verify.user.concepts=false
ontology.namelookups.useindex=false
ontology.nodefrequencymap.utilize=true
ontology.nodefrequencymap.utilize.chris=false
ontology.nodefrequencymap.utilize.erik=false
ontology.nodefrequencymap.utilize.robbie=false
ontology.nodefrequencymap.utilize.jim=true

data.directory=/opt/interests/testdata/
nlp.directory=/opt/interests/data/models/
topicindex.directory=/opt/interests/testdata/topicindex/

solr.endpoint=http://system76.playpen.gravity.com:8983/solr


ingestion.retrieve.from.lastupdate.only=false
ingestion.retrieve.friends=true
ingestion.crawl.friends=true
ingestion.twitter.firehose.url=https://stream.gnip.com:443/accounts/ProjectRover/publishers/twitter/streams/sample10/prod.json
ingestion.twitter.firehose.username=
ingestion.twitter.firehose.password=
ingestion.twitter.firehose.percent=1.0
ingestion.twitter.follower.max.fetch=50000
ingestion.twitter.consumer.key=
ingestion.twitter.consumer.secret=
ingestion.twitter.sleep.on.rate.limt=false
ingestion.wordpress.firehose.url=http://xmpp.wordpress.com:8008/posts.json
ingestion.wordpress.firehose.username=
ingestion.wordpress.firehose.password=
ingestion.wordpress.firehose.enabled=true
ingestion.wordpress.subsites.enabled=false
ingestion.aol.hosts=

graph.use.external=false

superfeedr.username=
superfeedr.password=

recommendation.shards.username=
recommendation.shards.password=

recommendation.shards.aws.username=
recommendation.shards.aws.password=
recommendation.shards.aws.host=db-reco-shards.aws.prod.grv

recommendation.widget.showDevWidget=true
recommendation.widget.showDevWidget.ahiniker=true
recommendation.widget.showDevWidget.robbie=false
recommendation.widget.configuration.db=configuration
recommendation.widget.configuration.db.cache.ttlSeconds=300
recommendation.widget.configuration.read.host=db-development.aws.prod.grv
recommendation.widget.configuration.read.host.robbie=db-configuration-slave.prod.grv
recommendation.widget.configuration.read.host.akash=db-configuration.prod.grv
recommendation.widget.configuration.read.host.jdecamp14=db-configuration.prod.grv
recommendation.widget.configuration.read.host.erik=db-configuration.prod.grv
recommendation.widget.configuration.read.host.tchappell=db-configuration.prod.grv
recommendation.widget.configuration.read.host.cyberpunk=db-configuration.prod.grv
recommendation.widget.configuration.read.host.BUILD_ENV=db-development.aws.prod.grv
recommendation.widget.configuration.read.username=
recommendation.widget.configuration.read.password=
recommendation.widget.configuration.write.host=db-development.aws.prod.grv
#recommendation.widget.configuration.write.host.robbie=db-configuration-master.prod.grv
recommendation.widget.configuration.write.host.runger=db-configuration.prod.grv
recommendation.widget.configuration.write.host.ahiniker=db-configuration-master.prod.grv
recommendation.widget.configuration.write.host.akash=db-configuration.prod.grv
recommendation.widget.configuration.write.host.agrealish14=db-configuration.prod.grv
recommendation.widget.configuration.write.host.jdecamp14=db-configuration.prod.grv
recommendation.widget.configuration.write.host.evictor=db-configuration.prod.grv
recommendation.widget.configuration.write.host.tchappell=db-configuration.prod.grv
recommendation.widget.configuration.write.host.BUILD_ENV=db-development.aws.prod.grv
recommendation.widget.configuration.write.username=
recommendation.widget.configuration.write.password=
recommendation.widget.configuration.dlPlacementSettings.cache=false
recommendation.widget.configuration.staticWidgetSettings.cache=false
recommendation.widget.servlet.prefix=/recommendation
recommendation.widget.servlet.secure.prefix=https://localhost:8080/recommendation
recommendation.api.servlet.prefix=/api/intelligence

recommendation.apidUserGuidSync.syncProbability=1

recommendation.extension.doBrowserCaching=false

siteservice.meta.doCache=false
siteservice.meta.doCache.erik=true
siteservice.meta.doCache.chris=false
siteservice.meta.doCache.ahiniker=false
siteservice.meta.doCache.runger=true
siteservice.meta.doCache.evictor=true
siteservice.meta.doCache.jason.sylvester=false
siteservice.meta.doCache.robbie=true
siteservice.meta.doCache.tchappell=false
siteservice.meta.doCache.agrealish14=false
siteservice.meta.doCache.jdecamp14=false

recommendation.filter.geo.enabled=true
recommendation.filter.geo.enabled.ahiniker=true
recommendation.filter.geo.enabled.evictor=false
recommendation.filter.geo.enabled.jason.sylvester=false
recommendation.filter.geo.enabled.akash=false
recommendation.filter.geo.enabled.agrealish14=false
recommendation.filter.geo.enabled.jdecamp14=false
recommendation.filter.geo.enabled.robbie=false

recommendation.filter.device.enabled=true
recommendation.filter.device.enabled.ahiniker=true
recommendation.log.redirect.prefix=http://localhost:8080/302/redirect
recommendation.log.redirect.prefixSecure=https://localhost:8080/302/redirect

recommendation.filter.mobileOs.enabled=true

mysql.connectionProvider.setTransactionIsolation=false

recommendations.maintenance.WIDGETS_FAILOVER=true

assets.prefix=http://localhost:8080
assets.prefix.secure=https://localhost:1443
assets.staticCdnPrefix=//static.grvcdn.com
assets.staticCdnPrefix.agrealish14=http://localhost:8080
assets.staticCdnPrefix.ahiniker=http://localhost:8080
assets.cacheAssetVersions=false
assets.showAssetManifestErrorTraces=false
assets.manifest.cache=false

api.warmCache.DEVELOPMENT=false
api.warmCache.ahiniker=false
api.warmCache.runger=false
api.warmCache.evictor=false
api.warmCache.jason.sylvester=false
#api.warmCache.robbie=true

api.warmCache.akash=false

recommendation.segments.doCache.chris=false
recommendation.segments.doCache.runger=true
recommendation.segments.doCache.ahiniker=true
recommendation.segments.doCache.evictor=true
recommendation.segments.doCache.agrealish14=true
recommendation.segments.doCache.jdecamp14=true
#recommendation.segments.doCache.robbie=true

algosettings.use.zookeper=false
algosettings.use.zookeper.evictor=true
decorators.activeCampaignsOnly.useActiveCampaignKeyCache=false
decorators.exchangeContentSourcesFilter.useAllExchangeMetaCache=false

# elastic search host info
grv-prod-es-data.es.cluster.name=prod-es-data
grv-prod-es-data.es.cluster.name.jdecamp14=prod-es-data2
grv-prod-es-data.es.cluster.name.robbie=prod-es-data2
grv-prod-es-data.es.cluster.fullname=prod-es-data.aws.prod.grv
grv-prod-es-data.es.cluster.fullnameAndPort=prod-es-data.aws.prod.grv:80
grv-prod-es-data.es.cluster.fullname.jdecamp14=prod-es-data2.aws.prod.grv
grv-prod-es-data.es.cluster.fullname.robbie=prod-es-data2.aws.prod.grv
grv-prod-es-data.es.cluster.fullnameAndPort.jdecamp14=prod-es-data2.aws.prod.grv:80
grv-prod-es-data.es.cluster.fullnameAndPort.robbie=prod-es-data2.aws.prod.grv:80

# remote job execution
grvcloud.jvm\:xx\:sysprop\:logging\:properties=-Dlogging.properties=/logging.properties
grvcloud.jvm\:xx\:sysprop\:grvcloud\:remote\:execution=-Dgrvgrid.remote.execution=true
grvcloud.jvm\:xx\:permgen=-XX:MaxPermSize=768M
grvcloud.remote-runtime\:jar-cache=.jar-cache

# Verbose output for ViEngine
#grvcloud.node\:config-trace=true

# Hadoop gateway
grvcloud.jvm\:xx\:mx.hadoopGateway=-Xmx8g
grvcloud.jvm\:exec-command.hadoopGateway=hadoop_java

# Spark Shell
grvcloud.jvm\:xx\:mx.spark-shell=-Xmx8g
grvcloud.jvm\:exec-command.spark-shell=hadoop_java
#grvcloud.jvm\:xx\:spark\:shell\:colorize.ahiniker=-Dspark.shell.colorize=false


# Disable heartbeat timeout
grvcloud.jvm\:xx\:heartbeat\:timeout.hadoopGateway=-Dorg.gridkit.telecontrol.slave.heart-beat-timeout=2147483647
grvcloud.jvm\:xx\:heartbeat\:timeout.jenkinsCluster=-Dorg.gridkit.telecontrol.slave.heart-beat-timeout=2147483647
grvcloud.jvm\:xx\:heartbeat\:timeout.spark-shell=-Dorg.gridkit.telecontrol.slave.heart-beat-timeout=2147483647

# Spark master
#grvcloud.jvm\:xx\:sysprop\:spark\:master.spark-shell.ahiniker=-Dspark.master=yarn-client
grvcloud.jvm\:xx\:sysprop\:spark\:dynamicAllocation\:maxExecutors.ahiniker=-Dspark.dynamicAllocation.maxExecutors=1024

# Remote Debugger
#grvcloud.jvm\:xx\:debug.spark-shell.ahiniker=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005
#grvcloud.jvm\:xx\:debug.hadoopGateway.jdecamp14=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005
#grvcloud.jvm\:xx\:debug.hadoopGateway.apatel=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5006
#grvcloud.jvm\:xx\:debug.spark-shell.robbie=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5420

grvcloud.remote\:account.jdecamp14=tdecamp
grvcloud.remote\:account.joperry15=jperry
grvcloud.remote\:account.akash=apatel
grvcloud.remote\:account.jengelman14=jengelman
grvcloud.remote\:account.tchappell14=tchappell
# To print out the logs locally by making the dev box the driver
#grvcloud.jvm\:xx\:sysprop\:spark\:master.jdecamp14=-Dspark.master=yarn-client


gravity.eventlogging.key=
gravity.eventlogging.secret=
gravity.eventlogging.bucket=grv-logevents

# traffic exchange reporting
traffic-exchange.reporting.url=https://1v7ykrfaya.execute-api.us-east-1.amazonaws.com/prod/omni
traffic-exchange.reporting.api-key=clsOqh5KEhbISp0FjHg162F3sOc6mdhUKIKcXQ10